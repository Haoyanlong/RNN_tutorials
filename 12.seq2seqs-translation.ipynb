{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation with a Sequence to Sequence Network and Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import unicodedata\n",
    "import codecs\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable as V\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models\n",
    "from torchvision import transforms as T\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Load data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### indexing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.word2count = {}\n",
    "        self.word2index = {}\n",
    "        self.index2word = {0:\"SOS\", 1:\"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "    \n",
    "    \n",
    "    def index_words(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.index_word(word)\n",
    "    \n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading and decoding files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Files are all in Unicode, turn Unicode characters to ASCII\n",
    "# Turn a Unicode string to plain ASCII\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "# Lowercase, trim, and remove non-letter character\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "# Read the files we split file into lines, and then split lines into pairs.\n",
    "# The files are all English to other language.\n",
    "# if we want to translate from Other language to English added reverse flag to reverse pairs.\n",
    "def read_langs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    \n",
    "    # Read the file and split into lines\n",
    "    with codecs.open('./data/eng-fra/%s_%s.txt' % (lang1, lang2), 'r', 'utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalize_string(s) for s in line.split('\\t')] for line in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instance\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "    \n",
    "    return input_lang, output_lang, pairs\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering sentences\n",
    "\n",
    "we'll trim the data set to only relatively short and simple sentences.\n",
    "Here the maximum length is 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "good_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \"\n",
    ")\n",
    "\n",
    "def filter_pair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "p[0].startswith(good_prefixes)\n",
    "\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The full process for preparing the data is:\n",
    "* * *\n",
    "- Read text file and split into lines, split lines into pairs\n",
    "- Normalize text filter by length and content\n",
    "- Make word lists from sentences in pairs\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_data(lang1_name, lang2_name, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1_name, lang2_name, reverse)\n",
    "    print(\"Read %d sentence pairs\" % len(pairs))\n",
    "    \n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(\"Trimmed to %d sentence pairs\" % len(pairs))\n",
    "    \n",
    "    print(\"Indexing words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.index_words(pair[0])\n",
    "        output_lang.index_words(pair[1])\n",
    "        \n",
    "    return input_lang, output_lang, pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 149861 sentence pairs\n",
      "Trimmed to 9551 sentence pairs\n",
      "Indexing words...\n",
      "[u'you re pathetic .', u'vous etes pathetique .']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepare_data('eng', 'fra')\n",
    "\n",
    "# Print an example pair\n",
    "print(random.choice(pairs))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turning training data into Tensors/Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return a list of indexes, one for each word in the sentence\n",
    "def indexes_from_sentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def variable_from_sentence(lang, sentence):\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    \n",
    "    # Add EOS_token\n",
    "    indexes.append(EOS_token)\n",
    "    var = V(t.LongTensor(indexes).view(-1, 1))\n",
    "    if t.cuda.is_available():\n",
    "        var = var.cuda()\n",
    "    return var\n",
    "\n",
    "def variable_from_pair(pair):\n",
    "    input_variable = variable_from_sentence(input_lang, pair[0])\n",
    "    output_variable = variable_from_sentence(output_lang, pair[1])\n",
    "    return input_variable, output_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=input_size, \n",
    "                                      embedding_dim=hidden_size)\n",
    "        self.gru = nn.GRU(input_size=hidden_size, \n",
    "                          hidden_size=hidden_size, \n",
    "                          num_layers=num_layers)\n",
    "        \n",
    "    \n",
    "    def forward(self, word_inputs, hidden):\n",
    "        # word_inputs: [234, 45, 23, 25, 1]\n",
    "        # Note: we run this all at once (over the whole input sequence)\n",
    "        seq_len = len(word_inputs)\n",
    "        # for gru: input size: [seq_len, batch_size, embeddding_dim]\n",
    "        embedded  = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        hidden = V(t.zeros((self.num_layers, 1, self.hidden_size)))\n",
    "        if t.cuda.is_available():\n",
    "            hidden = hidden.cuda()\n",
    "        return hidden   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the Bahdanau et al. model \n",
    "\n",
    "The decoder's inputs are the last RNN hidden state $s_{i-1}$, last output $y_{i-1}$, and \n",
    "all encoder outputs $h$.\n",
    "\n",
    "- embedding layer with inputs $y_{i-1}$\n",
    "  - embedded = embedding(last_rnn_output)\n",
    "- attention layer $\\alpha$ with inputs ($s_{i-1}$, $h_j$) and outputs $e_{ij}$, normalized to create $\\alpha_{ij}$\n",
    "  - attn_energies[j] = attn_layer(last_hidden, encoder_outputs[j])\n",
    "  - attn_weights = normalize(attn_energies)\n",
    "- context vector $c_{i}$ as an attention-weighted average of encoder outputs\n",
    "  - context = sum(attn_weights * encoder_outputs)\n",
    "- RNN layer(s) f with inputs($s_{i-1}$,$y_{i-1}$,$c_{i}$) and internal hidden state, outputting $s_{i}$\n",
    "  - rnn_input = concat(embedded, context)\n",
    "  - rnn_output, rnn_hidden = rnn(rnn_input, last_hidden)\n",
    "- an output layer g with inputs($y_{i-1}$, $s_i$, $c_i$), outputting $y_i$\n",
    "  - output = out(embedded, rnn_output, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BahdanauAttnDecoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, output_size, num_layers=1, dropout_p=0.1):\n",
    "        super(BahdanauAttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        # define parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # define layers\n",
    "        self.embedding = nn.Embedding(num_embeddings=output_size, embedding_dim=hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attn = GeneralAttn(hidden_size)\n",
    "        self.gru = nn.GRU(input_size=hidden_size * 2,\n",
    "                          hidden_size=hidden_size, \n",
    "                          num_layers=num_layers, \n",
    "                          dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "        # Note that we will only be running forward for a single decoder time step,\n",
    "        # but will use all encoder outputs\n",
    "        \n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1)  # S = 1 * B * N\n",
    "        word_embedded = self.dropout(word_embedded)\n",
    "        \n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "        attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B * 1 * N\n",
    "        \n",
    "        # Combine embedded input word and attended context, run through RNN\n",
    "        rnn_input = t.cat((word_embedded, context), 2)\n",
    "        output, hidden = self.gru(rnn_input, last_hidden)\n",
    "        \n",
    "        # Final output layer\n",
    "        output = output.squeeze(0)     # B * N\n",
    "        output = F.log_softmax(self.out(t.cat((output, context), 1)))\n",
    "        \n",
    "        # Return final output, hidden state, and attention weights(for visualization)\n",
    "        return output, hidden, attn_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting the Luong et al. model(s)\n",
    "\n",
    "$$\\alpha_{t}(s) = align(h_t, \\bar{h_s}) = \\frac{exp(score(h_t, \\bar{h_s}))}{\\sum_{s'}exp(score(h_t, \\bar{h_{s'}}))}$$\n",
    "\n",
    "\n",
    "$$\\begin{equation}\n",
    "score(h_t, \\bar{h_s}) = \\left\\{\n",
    "\\begin{aligned}\n",
    "h_t^T\\bar{h_s} & & dot    \\\\\n",
    "h_t^TW_{\\alpha}\\bar{h_s} & & general    \\\\\n",
    "v_{\\alpha}^TW_{\\alpha}[h_t;\\bar{h_s}] & & concat   \\\\\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "\\end{equation}$$\n",
    "\n",
    "式子中,$h_t$, $\\bar{h_s}$分别表示decoder, encoder的hidden state, 根据decoder的hidden和encoder的ouput来计算attention 权重\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    \n",
    "    def __init__(self, method, hidden_size, max_length=MAX_LENGTH):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
    "            self.other = nn.Parameter(t.FloatTensor(1, hidden_size))\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = len(encoder_outputs)\n",
    "        \n",
    "        # Create variable to store attention energies\n",
    "        attn_energies = V(t.zeros(seq_len))    # B * 1 * S\n",
    "        if t.cuda.is_available():\n",
    "            attn_energies = attn_energies.cuda()\n",
    "            \n",
    "        # Calculate energies for each encoder output\n",
    "        for i in range(seq_len):\n",
    "            attn_energies[i] = self.score(hidden, encoder_outputs[i])\n",
    "        \n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 * 1 * seq_len\n",
    "        return F.softmax(attn_energies).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    def score(self, hidden, encoder_output):\n",
    "        if self.method == 'dot':\n",
    "            energy = hidden.dot(encoder_output)\n",
    "            return energy\n",
    "    \n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            energy = hidden.dot(energy)\n",
    "            return energy\n",
    "        \n",
    "        else:\n",
    "            energy = self.attn(t.cat((hidden, encoder_output)), 1)\n",
    "            energy = self.other.dot(energy)\n",
    "            return energy     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build a decoder that plugs this Attn module in after the RNN to calculate attention weight, and apply those weights to the encoder outputs to get a context vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, attn_model, hidden_size, output_size, \n",
    "                 num_layers=1, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        # Keep parameters for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(num_embeddings=output_size, \n",
    "                                      embedding_dim=hidden_size)\n",
    "        self.gru = nn.GRU(input_size=hidden_size * 2,\n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=num_layers,\n",
    "                          dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "        \n",
    "        # Choose attention model\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "            \n",
    "    def forward(self, word_input, last_context, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time\n",
    "        \n",
    "        # word_input: embedding_dim\n",
    "        # Get the embedding of the current input word(last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1)   # S = 1 * B * N\n",
    "        \n",
    "        # Combine embedded input word and last context, run through RNN\n",
    "        rnn_input = t.cat((word_embedded, last_context.unsqueeze(0)), 2)\n",
    "        rnn_output, hidden = self.gru(rnn_input, last_hidden)\n",
    "        \n",
    "        # Calculate attention from current RNN state and all encoder outputs;\n",
    "        # apply to encoder outputs\n",
    "        attn_weights = self.attn(rnn_output.squeeze(0), encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))   # B * 1 * N\n",
    "        \n",
    "        # Final output layer (next word prediction) using the RNN hidden \n",
    "        # state and context vector\n",
    "        rnn_output = rnn_output.squeeze(0)     # S = 1 * B * N ---> B * N\n",
    "        context = context.squeeze(1)           # B * S = B * 1 * N ---> B * N\n",
    "        output = F.log_softmax(self.out(t.cat((rnn_output, context), 1)))\n",
    "        \n",
    "        # Return final output, hidden_state, and attention weights (for visualization)\n",
    "        return output, context, hidden, attn_weights\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing model\n",
    "\n",
    "To make sure the Encoder and Decoder model are working (and working together) we'll \n",
    "do a quick test with fake word inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_test:  EncoderRNN(\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (gru): GRU(10, 10, num_layers=2)\n",
      ")\n",
      "encoder_hidden:  Variable containing:\n",
      "(0 ,.,.) = \n",
      "   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "(1 ,.,.) = \n",
      "   0   0   0   0   0   0   0   0   0   0\n",
      "[torch.cuda.FloatTensor of size 2x1x10 (GPU 0)]\n",
      "\n",
      "encoder outputs:  torch.Size([3, 1, 10])\n",
      "encoder hidden:  torch.Size([2, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "encoder_test = EncoderRNN(input_size=10, hidden_size=10, num_layers=2)\n",
    "print(\"encoder_test: \", encoder_test)\n",
    "\n",
    "encoder_hidden = encoder_test.init_hidden()\n",
    "print(\"encoder_hidden: \", encoder_hidden)\n",
    "word_input = V(t.LongTensor([1, 2, 3]))\n",
    "if t.cuda.is_available():\n",
    "    encoder_test.cuda()\n",
    "    word_input = word_input.cuda()\n",
    "encoder_outputs, encoder_hidden = encoder_test(word_input, encoder_hidden)\n",
    "\n",
    "print(\"encoder outputs: \",encoder_outputs.size())\n",
    "print(\"encoder hidden: \", encoder_hidden.size())\n",
    "\n",
    "# print(encoder_outputs[-1] == encoder_hidden[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_test:  AttnDecoderRNN(\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (gru): GRU(20, 10, num_layers=2, dropout=0.1)\n",
      "  (out): Linear(in_features=20, out_features=10)\n",
      "  (attn): Attn(\n",
      "    (attn): Linear(in_features=10, out_features=10)\n",
      "  )\n",
      ")\n",
      "decoder output:  torch.Size([1, 10]) decoder hidden:  torch.Size([2, 1, 10]) decoder attn:  torch.Size([1, 1, 3])\n",
      "decoder output:  torch.Size([1, 10]) decoder hidden:  torch.Size([2, 1, 10]) decoder attn:  torch.Size([1, 1, 3])\n",
      "decoder output:  torch.Size([1, 10]) decoder hidden:  torch.Size([2, 1, 10]) decoder attn:  torch.Size([1, 1, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/common/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/common/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:47: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "decoder_test = AttnDecoderRNN(attn_model='general', \n",
    "                              hidden_size=10,\n",
    "                              output_size=10,\n",
    "                              num_layers=2)\n",
    "print(\"decoder_test: \", decoder_test)\n",
    "\n",
    "\n",
    "word_inputs = V(t.LongTensor([1, 2, 3]))\n",
    "decoder_attns = t.zeros(1, 3, 3)\n",
    "decoder_hidden = encoder_hidden\n",
    "decoder_context = V(t.zeros(1, decoder_test.hidden_size))\n",
    "\n",
    "if t.cuda.is_available():\n",
    "    decoder_test.cuda()\n",
    "    word_inputs = word_inputs.cuda()\n",
    "    decoder_context = decoder_context.cuda()\n",
    "\n",
    "for i in range(3):\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attn = \\\n",
    "    decoder_test(word_inputs[i], decoder_context, decoder_hidden, encoder_outputs)\n",
    "    \n",
    "    print(\"decoder output: \", decoder_output.size(),\n",
    "          \"decoder hidden: \", decoder_hidden.size(),\n",
    "          \"decoder attn: \", decoder_attn.size())\n",
    "    decoder_attns[0, i] = decoder_attn.squeeze(0).cpu().data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    loss = 0  # Added onto for each word\n",
    "    \n",
    "    # Get size of input and target sentences\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "    \n",
    "    # Run words through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = V(t.LongTensor([[SOS_token]]))\n",
    "    decoder_context = V(t.zeros(1, decoder.hidden_size))\n",
    "    decoder_hidden = encoder_hidden  # Use last hidden state from encoder to start decoder\n",
    "\n",
    "    if t.cuda.is_available():\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        decoder_context = decoder_context.cuda()\n",
    "    \n",
    "    # Choose whether to use teacher forcing\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Use the ground-truch target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = \\\n",
    "                decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs) \n",
    "            # print(\"decoder_output size: \", decoder_output[0].size())\n",
    "            # print(\"target_variable size: \", target_variable[di].size())\n",
    "            \n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]    # Next target is next input\n",
    "    else:\n",
    "        # Without teacher forcing: use network's own prediction as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = \\\n",
    "                decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            \n",
    "            # Get most likely word index (highest value) from output\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            decoder_input = V(t.LongTensor([[ni]]))   # Chosen word is next input\n",
    "            if t.cuda.is_available():\n",
    "                decoder_input = decoder_input.cuda()\n",
    "            \n",
    "            # Stop at end of sentence (not necessary when using known targets)\n",
    "            if ni == EOS_token: \n",
    "                break\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        t.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "        t.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to print time elapsed and estimated time remaining\n",
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (- %s)\" % (as_minutes(s), as_minutes(rs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run training\n",
    "\n",
    "With everything in place we can actually initialize a network and start training.\n",
    "To start, we initialize models, optimizers, and a loss function(criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input language num words:  2768\n",
      "output language num words:  4015\n"
     ]
    }
   ],
   "source": [
    "print(\"input language num words: \", input_lang.n_words)\n",
    "print(\"output language num words: \", output_lang.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder:  EncoderRNN(\n",
      "  (embedding): Embedding(2768, 500)\n",
      "  (gru): GRU(500, 500, num_layers=2)\n",
      ")\n",
      "decoder:  AttnDecoderRNN(\n",
      "  (embedding): Embedding(4015, 500)\n",
      "  (gru): GRU(1000, 500, num_layers=2, dropout=0.05)\n",
      "  (out): Linear(in_features=1000, out_features=4015)\n",
      "  (attn): Attn(\n",
      "    (attn): Linear(in_features=500, out_features=500)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "attn_model = 'general'\n",
    "hidden_size = 500\n",
    "num_layers = 2\n",
    "dropout_p = 0.05\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderRNN(input_size=input_lang.n_words,          # 2768\n",
    "                     hidden_size=hidden_size, \n",
    "                     num_layers=num_layers)                  # 2\n",
    "decoder = AttnDecoderRNN(attn_model=attn_model, \n",
    "                         hidden_size=hidden_size, \n",
    "                         output_size=output_lang.n_words,    # 4015\n",
    "                         num_layers=num_layers,              # 2\n",
    "                         dropout_p=dropout_p)\n",
    "\n",
    "# Move models to GPU\n",
    "if t.cuda.is_available():\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "print(\"encoder: \", encoder)\n",
    "print(\"decoder: \", decoder)\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Then set up variables for plotting and tracking progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configuring training\n",
    "n_epochs = 5000\n",
    "plot_every = 200\n",
    "print_every = 1000\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0     # Reset every print_every\n",
    "plot_loss_total = 0      # Reset every plot_every\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/common/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/common/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:47: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d01bcaaa3f29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     loss = train(input_variable, target_variable, \n\u001b[1;32m     11\u001b[0m                  \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                  encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Keep track of loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-9e6cc8f375e8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Without teacher forcing: use network's own prediction as the next input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_attention\u001b[0m \u001b[0;34m=\u001b[0m                 \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-178800095e24>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, word_input, last_context, last_hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Calculate attention from current RNN state and all encoder outputs;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# apply to encoder outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# B * 1 * N\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/common/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-b6c3e4031e55>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Calculate energies for each encoder output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mattn_energies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Normalize energies to weights in range 0 to 1, resize to 1 * 1 * seq_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-b6c3e4031e55>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, hidden, encoder_output)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'general'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menergy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0menergy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Begin\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    training_pair = variable_from_pair(random.choice(pairs))\n",
    "    input_variable = training_pair[0]\n",
    "    target_variable = training_pair[1]\n",
    "    \n",
    "    # Run the train function\n",
    "    loss = train(input_variable, target_variable, \n",
    "                 encoder, decoder, \n",
    "                 encoder_optimizer, decoder_optimizer, criterion)\n",
    "    \n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "    \n",
    "    if epoch == 0: continue\n",
    "    \n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = '%s (%d %d%%) %.4f' % \\\n",
    "                        (time_since(start, epoch / n_epochs),\n",
    "                         epoch, epoch / n_epochs * 100, print_loss_avg)\n",
    "        print(print_summary)\n",
    "        \n",
    "    if epoch % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_avg = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Plotting training loss\n",
    "\n",
    "Plotting is done with matplotlib, using the array plot_losses that was created while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)  # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the network\n",
    "\n",
    "Evaluation is mostly the same as training, but there are no targets. Instead we always feed the decoder's predictions back to itself. Every time it predicts a word, we add it to the output string. If it predicts the EOS token we stop there. We also store the decoder's \n",
    "attention outputs for each step to display later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=MAX_LENGTH):\n",
    "    \n",
    "    input_variable = variable_from_sentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    \n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = V(t.LongTensor([SOS_token]))   # SOS\n",
    "    decoder_context = V(t.zeros(1, decoder.hidden_size))\n",
    "    \n",
    "    if t.cuda.is_available():\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        decoder_context = decoder_context.cuda()\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_words = []\n",
    "    decoder_attentions = t.zeros(max_length, max_length)\n",
    "    \n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        \n",
    "        decoder_output, decoder_context, decoder_hidden, decoder_attention = \\\n",
    "            decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "        decoder_attentions[di, :decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "        \n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoder_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoder_words.append(output_lang.index2word[ni])\n",
    "        \n",
    "        # Next input is chosen word\n",
    "        decoder_input = V(t.LongTensor([[ni]]))\n",
    "        if t.cuda.is_available():\n",
    "            decoder_input = decoder_input.cuda()\n",
    "    return decoder_words, decoder_attentions[:di+1, :len(encoder_outputs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate random sentences from the training set and print out the input, target, and \n",
    "# output to make some subjective quality judgements\n",
    "def evaluate_randomly():\n",
    "    pair = random.choice(pairs)\n",
    "    \n",
    "    output_words, decoder_attn = evaluate(pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    \n",
    "    print('raw input: ', pair[0])\n",
    "    print('target: ', pair[1])\n",
    "    print('predict output: ', output_sentence)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw input:  you re all set .\n",
      "target:  vous etes tous prets .\n",
      "predict output:  pareille deborde concentration troubles abandonne concentration honte abandonne honte fixee\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/common/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/common/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:47: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing attention\n",
    "A useful property of the attention mechanism is its highly interpretable outputs. Because it is used to weight specific encoder outputs of the input sequence, we can imagine looking where the network is focused most at each time step.\n",
    "\n",
    "You could simply run plt.matshow(attentions) to see attention output displayed as a matrix, with the columns being input steps and rows being output steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sentence:  i m not going to get involved .\n",
      "target_sentence:  je suis une femme mariee .\n",
      "output words:  [u'asociale', u'asociale', u'confronte', u'asociale', u'idiots', u'excellent', u'malade', u'malade', u'polies', u'commande']\n",
      "attentions:  \n",
      " 0.0928  0.1033  0.1125  0.1138  0.1499  0.1493  0.1127  0.0906  0.0751\n",
      " 0.0915  0.1019  0.1129  0.1182  0.1466  0.1429  0.1110  0.0917  0.0832\n",
      " 0.0914  0.0984  0.1052  0.1216  0.1433  0.1472  0.1138  0.0886  0.0904\n",
      " 0.1010  0.1014  0.1114  0.1123  0.1248  0.1264  0.1125  0.1015  0.1088\n",
      " 0.0970  0.1015  0.1090  0.1145  0.1239  0.1256  0.1143  0.1039  0.1104\n",
      " 0.0907  0.0857  0.0846  0.1028  0.1309  0.1373  0.1278  0.1159  0.1243\n",
      " 0.0900  0.0845  0.0813  0.0925  0.1212  0.1369  0.1287  0.1203  0.1446\n",
      " 0.0973  0.0961  0.0940  0.0996  0.1280  0.1259  0.1175  0.1093  0.1322\n",
      " 0.1091  0.1117  0.1098  0.1064  0.1315  0.1158  0.1070  0.0954  0.1133\n",
      " 0.1038  0.1066  0.0954  0.1050  0.1312  0.1309  0.1128  0.0990  0.1153\n",
      "[torch.FloatTensor of size 10x9]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/common/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/common/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:47: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd5e81452d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAEaCAYAAAAxNOpxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFETwgYL+C3ojwoqVWi+RAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5e8311d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_sentence = random.choice(pairs)[0]\n",
    "target_sentence = random.choice(pairs)[1]\n",
    "print(\"input sentence: \", input_sentence)\n",
    "print(\"target_sentence: \", target_sentence)\n",
    "\n",
    "output_words, attentions = evaluate(input_sentence)\n",
    "print(\"output words: \", output_words)\n",
    "print(\"attentions: \", attentions)\n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better experience we will do the extra work of adding axes and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cas = ax.matshow(attentions.numpy(), cmap = 'bone')\n",
    "    fig.colorbar(cas)\n",
    "    \n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "    \n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "def evaluate_and_show_attention(input_sentence):\n",
    "    output_words, attentions = evaluate(input_sentence)\n",
    "    print(\"input sentence: \", input_sentence)\n",
    "    print(\"output sentence: \", ' '.join(output_words))\n",
    "    \n",
    "    show_attention(input_sentence, output_words, attentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/common/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/common/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:47: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sentence:  she is in low spirits today .\n",
      "output sentence:  immoral immoral etala etala tot solitaires solitaires serre brulures perspicace\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAAEXCAYAAAAup8hAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKz0nMjMrPScyMys9JzIzK73/Boxo3wNDqobrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5e996a650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_and_show_attention(random.choice(pairs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/common/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/common/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:47: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sentence:  i am ready to die .\n",
      "output sentence:  fabuleux ambitieuse pareille audace brillants brillants audace brillants cloturer impatients\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR4AAAEXCAYAAAB7xiseAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5e979b4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_and_show_attention(random.choice(pairs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/common/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/common/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:47: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sentence:  you re the teacher .\n",
      "output sentence:  fabuleux ambitieuse pareille adversaire conteste contente contente prevu contente contente\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAEYCAYAAACgIGhkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5EcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5e8bd5410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_and_show_attention(random.choice(pairs)[0])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
