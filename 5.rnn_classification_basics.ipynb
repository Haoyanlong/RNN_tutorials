{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable as V\n",
    "import torch.utils.data as Data\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from pyfile.name_dataset import NameDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters and DataLoaders\n",
    "HIDDEN_SIZE = 100\n",
    "N_CHARS = 128 \n",
    "N_CLASSES = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # Note: we run this all at once (over the whole input sequence)\n",
    "        \n",
    "        # input = B * S. size(0) = B\n",
    "        batch_size = inputs.size(0)\n",
    "        \n",
    "        # input: B * S --(transpose) --> S * B\n",
    "        inputs = inputs.t()\n",
    "        \n",
    "        # Embedding S * B --> S * B * I (embedding size)\n",
    "        print(\"inputs size: \", inputs.size())\n",
    "        embeded = self.embedding(inputs)\n",
    "        print(\"embedding size: \", embeded.size())\n",
    "        \n",
    "        # Make a hidden\n",
    "        hidden = self._init_hidden(batch_size)\n",
    "        \n",
    "        output, hidden = self.gru(embeded, hidden)\n",
    "        print(\"gru hidden output size: \", hidden.size())\n",
    "        # Use the last layer output as FC's input\n",
    "        # No need th unpack, since we are going to use hidden\n",
    "        fc_output = self.fc(hidden)\n",
    "        print(\"fc output size: \", fc_output.size())\n",
    "        \n",
    "        return fc_output\n",
    "    \n",
    "    def _init_hidden(self, batch_size):\n",
    "        hidden = t.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return V(hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Help functions\n",
    "\n",
    "def str2ascii_arr(msg):\n",
    "    # ord: char map to ascii\n",
    "    arr = [ord(c) for c in msg]\n",
    "    return arr, len(arr)\n",
    "\n",
    "# pad sequences and sort the tensor\n",
    "def pad_sequences(vectorized_seqs, seq_lengths):\n",
    "    seq_tensor = t.zeros((len(vectorized_seqs), seq_lengths.max())).long()\n",
    "    for idx, (seq, seq_len) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
    "        seq_tensor[idx, :seq_len] = t.LongTensor(seq)\n",
    "    return seq_tensor\n",
    "\n",
    "# Create necessary variables, lengths, and target\n",
    "def make_variables(names):\n",
    "    sequence_and_length = [str2ascii_arr(name) for name in names]\n",
    "    # print(\"sequence_and_lengths: \", sequence_and_length)\n",
    "    \n",
    "    vectorized_seqs = [sl[0] for sl in sequence_and_length]\n",
    "    seq_lengths = t.LongTensor([sl[1] for sl in sequence_and_length])\n",
    "    # print(\"vectorized_seqs: \", vectorized_seqs)\n",
    "    # print(\"seq_lengths: \", seq_lengths)\n",
    "    padSequences = pad_sequences(vectorized_seqs, seq_lengths)\n",
    "    return padSequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# names = ['Haoyanlong', 'Xueben', 'Yanshuangying']\n",
    "\n",
    "# pad_sequences = make_variables(names)\n",
    "# print(\"pad_sequences: \", pad_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs size:  torch.Size([6, 1])\n",
      "embedding size:  torch.Size([6, 1, 100])\n",
      "gru hidden output size:  torch.Size([1, 1, 100])\n",
      "fc output size:  torch.Size([1, 1, 18])\n",
      "in Variable containing:\n",
      "  97  100  121  108  111  118\n",
      "[torch.LongTensor of size 1x6]\n",
      " out Variable containing:\n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.2741 -0.0228 -0.0815 -0.0937 -0.0627 -0.4570  0.3429 -0.3141 -0.0211\n",
      "\n",
      "Columns 9 to 17 \n",
      "   0.0535 -0.2229 -0.2405 -0.0655 -0.1692 -0.1103  0.0922  0.3456  0.0541\n",
      "[torch.FloatTensor of size 1x1x18]\n",
      "\n",
      "*************************************\n",
      "inputs size:  torch.Size([5, 1])\n",
      "embedding size:  torch.Size([5, 1, 100])\n",
      "gru hidden output size:  torch.Size([1, 1, 100])\n",
      "fc output size:  torch.Size([1, 1, 18])\n",
      "in Variable containing:\n",
      " 115  111  108   97  110\n",
      "[torch.LongTensor of size 1x5]\n",
      " out Variable containing:\n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.1535 -0.0400  0.0799  0.0614 -0.1515 -0.1010 -0.1350 -0.0872  0.1766\n",
      "\n",
      "Columns 9 to 17 \n",
      "  -0.0186  0.2866 -0.2290 -0.2586  0.1083  0.3120  0.2634  0.2101  0.1260\n",
      "[torch.FloatTensor of size 1x1x18]\n",
      "\n",
      "*************************************\n",
      "inputs size:  torch.Size([4, 1])\n",
      "embedding size:  torch.Size([4, 1, 100])\n",
      "gru hidden output size:  torch.Size([1, 1, 100])\n",
      "fc output size:  torch.Size([1, 1, 18])\n",
      "in Variable containing:\n",
      " 104   97  114  100\n",
      "[torch.LongTensor of size 1x4]\n",
      " out Variable containing:\n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.2456 -0.0900 -0.1486  0.0428 -0.1626 -0.0962 -0.0531 -0.1295 -0.0589\n",
      "\n",
      "Columns 9 to 17 \n",
      "   0.1361 -0.0280 -0.1414 -0.2154 -0.3195 -0.0247  0.1933  0.0723 -0.1203\n",
      "[torch.FloatTensor of size 1x1x18]\n",
      "\n",
      "*************************************\n",
      "inputs size:  torch.Size([3, 1])\n",
      "embedding size:  torch.Size([3, 1, 100])\n",
      "gru hidden output size:  torch.Size([1, 1, 100])\n",
      "fc output size:  torch.Size([1, 1, 18])\n",
      "in Variable containing:\n",
      " 115   97  110\n",
      "[torch.LongTensor of size 1x3]\n",
      " out Variable containing:\n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.1584  0.0453  0.0782  0.0936 -0.2143 -0.0769 -0.1328 -0.0667  0.1292\n",
      "\n",
      "Columns 9 to 17 \n",
      "   0.0001  0.3341 -0.1966 -0.3041  0.1096  0.2600  0.2424  0.1842  0.1618\n",
      "[torch.FloatTensor of size 1x1x18]\n",
      "\n",
      "*************************************\n",
      "inputs size:  torch.Size([6, 4])\n",
      "embedding size:  torch.Size([6, 4, 100])\n",
      "gru hidden output size:  torch.Size([1, 4, 100])\n",
      "fc output size:  torch.Size([1, 4, 18])\n",
      "batch in \n",
      "  97  100  121  108  111  118\n",
      " 115  111  108   97  110    0\n",
      " 104   97  114  100    0    0\n",
      " 115   97  110    0    0    0\n",
      "[torch.LongTensor of size 4x6]\n",
      " batch out Variable containing:\n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.2741 -0.0228 -0.0815 -0.0937 -0.0627 -0.4570  0.3429 -0.3141 -0.0211\n",
      "  0.1431  0.0525  0.0712  0.2517 -0.1866 -0.0161 -0.2053 -0.0927  0.1154\n",
      "  0.0967  0.0067  0.0086  0.3014 -0.1650  0.1096 -0.2166 -0.1081  0.0094\n",
      "  0.0687  0.0533  0.1326  0.3706 -0.2104  0.1927 -0.2482 -0.1468  0.0345\n",
      "\n",
      "Columns 9 to 17 \n",
      "   0.0535 -0.2229 -0.2405 -0.0655 -0.1692 -0.1103  0.0922  0.3456  0.0541\n",
      " -0.1710  0.0493 -0.1397 -0.1301 -0.1801  0.2492 -0.1923  0.1479  0.0880\n",
      " -0.2455 -0.1676 -0.1195  0.0237 -0.4662  0.1410 -0.4447  0.1917 -0.0209\n",
      " -0.3296 -0.1718 -0.1065  0.0499 -0.3990  0.1620 -0.5639  0.1979  0.0502\n",
      "[torch.FloatTensor of size 1x4x18]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = ['adylov', 'solan', 'hard', 'san']\n",
    "classifier = RNNClassifier(N_CHARS, HIDDEN_SIZE, N_CLASSES)\n",
    "\n",
    "for name in names:\n",
    "    arr, _ = str2ascii_arr(name)\n",
    "    inp = V(t.LongTensor([arr]))\n",
    "    output = classifier(inp)\n",
    "    print(\"in\", inp, \"out\", output)\n",
    "    print(\"*************************************\")\n",
    "\n",
    "inputs = make_variables(names)\n",
    "out = classifier(inputs)\n",
    "print(\"batch in\", inputs, \"batch out\", out)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
