{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable as V\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from pyfile.text_loader import TextDataset\n",
    "import pyfile.seq2seq_models as sm\n",
    "from pyfile.seq2seq_models import str2tensor, EOS_token, SOS_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS_token:  1\n",
      "SOS_token:  \u0000\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_SIZE = 100\n",
    "N_LAYERS = 1\n",
    "BATCH_SIZE = 1\n",
    "N_EPOCH = 100\n",
    "N_CHARS = 128 # ASCII\n",
    "\n",
    "print(\"EOS_token: \", EOS_token)   # 1\n",
    "print(\"SOS_token: \", SOS_token)   # SOS_token = chd(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train for a given src and target\n",
    "def train(src, target):\n",
    "    src_var = str2tensor(src)\n",
    "    target_var = str2tensor(target, eos=True)    # Add the EOS token\n",
    "    \n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(src_var, encoder_hidden)\n",
    "    \n",
    "    hidden = encoder_hidden\n",
    "    loss = 0\n",
    "    \n",
    "    for c in range(len(target_var)):\n",
    "        # First, we feed SOS\n",
    "        # others, use teacher forcing\n",
    "        token = target_var[c - 1] if c else str2tensor(SOS_token)\n",
    "        output, hidden = decoder(token, hidden)\n",
    "        loss += criterion(output, target[c])\n",
    "    \n",
    "    eocoder.zero_grad()\n",
    "    decoder.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / len(target_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple test to show how our network works\n",
    "def test():\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    word_input = str2tensor('hello')\n",
    "    encoder_outputs, encoder_hidden = encoder(word_input, encoder_hidden)\n",
    "    print(\"encoder outputs: \", encoder_outputs)\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    word_target = str2tensor('pytorch')\n",
    "    for c in range(len(word_target)):\n",
    "        decoder_output, decoder_hidden = decoder(word_target[c], decoder_hidden)\n",
    "        print(\"decoder output size: \", decoder_output.size())\n",
    "        print(\"decoder hidden size: \", decoder_hidden.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Translate the given input\n",
    "def translate(enc_input='thisissungkim.iloveyou.', predict_len=100, temperature=0.9):\n",
    "    input_var = str2tensor(enc_input)\n",
    "    \n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_var, encoder_hidden)\n",
    "    \n",
    "    hidden = encoder_hidden\n",
    "    \n",
    "    predicted = ''\n",
    "    dec_input = str2tensor(SOS_token)\n",
    "    for c in range(predict_len):\n",
    "        output, hidden = decoder(dec_input, hidden)\n",
    "        \n",
    "        # Sample from the network as a multi nominal distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = t.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Stop at the EOS\n",
    "        if top_i is EOS_token:\n",
    "            break\n",
    "        \n",
    "        predicted_char = chr(top_i)\n",
    "        predicted += predicted_char\n",
    "        \n",
    "        dec_input = str2tensor(predicted_char)\n",
    "    \n",
    "    return enc_input, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# main\n",
    "\n",
    "encoder = sm.EncoderRNN(N_CHARS, HIDDEN_SIZE, N_LAYERS)\n",
    "decoder = sm.DecoderRNN(HIDDEN_SIZE, N_CHARS, N_LAYERS)\n",
    "\n",
    "if t.cuda.is_available():\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "print(\"encoder: \", encoder)\n",
    "print(\"decoder: \", decoder)\n",
    "test()\n",
    "\n",
    "\n",
    "# Optimizer and Loss\n",
    "params = list(encoder.parameters()) + list(decoder.parameters())\n",
    "optimizer = optim.Adam(params, lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_dataloader = Data.DataLoader(dataset=TextDataset(),\n",
    "                                   batch_size=BATCH_SIZE,\n",
    "                                   shuffle=True,\n",
    "                                   num_workers=2)\n",
    "print(\"Training for %d epochs...\" % N_EPOCH)\n",
    "\n",
    "for epoch in range(1, N_EPOCH + 1):\n",
    "    for i, (srcs, targets) in enumerate(train_dataloader):\n",
    "        train_loss = train(srcs[0], targets[0])      # Batch is 1\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch: (%d %d%%) Loss: %.4f\" % \n",
    "                  (epoch, epoch / N_EPOCH * 100, train_loss))\n",
    "            print(translate(srcs[0]), '\\n')\n",
    "            print(translate(), '\\n')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
